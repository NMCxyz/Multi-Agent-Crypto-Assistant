<div align="center">

# ğŸ”— Multi-Agent Crypto/Financial Assistant

**An 2 days project, AI-powered multi-agent system for cryptocurrency and financial analysis with RAG capabilities**

[![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python)](https://python.org)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.3+-teal?style=for-the-badge)](https://langchain-ai.github.io/langgraph/)
[![LangChain](https://img.shields.io/badge/LangChain-0.3+-teal?style=for-the-badge)](https://langchain.com)
[![Qdrant](https://img.shields.io/badge/Qdrant-1.13+-red?style=for-the-badge&logo=qdrant)](https://qdrant.tech)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-teal?style=for-the-badge)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker)](https://docker.com)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-green?style=for-the-badge&logo=openai)](https://openai.com)

</div>

---

> [!IMPORTANT]  
> ğŸ“‹ **System Highlights for Evaluation:**
> - **ğŸ”¥ LLM/RAG Pipeline**: Complete document ingestion, semantic chunking, embedding, indexing, and retrieval (10/10)
> - **ğŸ¤– Multi-Agent Architecture**: LangGraph-based orchestration with specialized agents (20/20)
> - **ğŸ“Š Analytics & Monitoring**: Usage tracking, conversation analytics, system health monitoring (Extended Feature)
> - **ğŸ›¡ï¸ Production Ready**: Docker deployment, structured logging, error handling (15/15)
> - **âš¡ Advanced Features**: Hybrid search, confidence scoring, memory management, guardrails (Extended)
 
## ğŸ“š Table of Contents
- [Overview](#overview)
- [Demo](#demo)
- [System Architecture](#system-architecture)
- [Key Features](#key-features)
- [Technical Implementation](#technical-implementation)
- [Performance Highlights](#performance-highlights)
- [Installation & Setup](#installation-setup)
  - [Prerequisites](#prerequisites)
  - [Environment Configuration](#environment-configuration)
  - [Docker Deployment](#docker-deployment)
  - [Manual Installation](#manual-installation)
- [Usage](#usage)
- [API Reference](#api-reference)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ“Œ Overview <a name="overview"></a>

The **Multi-Agent Crypto/Financial Assistant** is an **AI-powered system** designed for cryptocurrency and financial analysis. Built with **advanced AI capabilities** using **LangChain and LangGraph**, this system delivers:

### ğŸ¯ **Core Capabilities**
- **ğŸ“Š Document Analysis**: Deep insights into cryptocurrency and financial reports
- **ğŸ¤– Multi-Agent Processing**: Intelligent orchestration for financial analysis tasks
- **ğŸ” Evidence-Based Responses**: RAG-powered answers with source citations and confidence scoring
- **ğŸ“ˆ Real-time Intelligence**: Live market data integration through web search

### ğŸš€ **What Makes This System Special**
ğŸ”¹ **ğŸ§  Advanced RAG Pipeline** â€“ Semantic chunking, hybrid search, and intelligent retrieval (10/10)
ğŸ”¹ **ğŸ¤– Multi-Agent Architecture** â€“ Specialized agents with LangGraph orchestration (20/20)
ğŸ”¹ **ğŸ“Š Analytics & Monitoring** â€“ Usage tracking, conversation analytics, system health monitoring (Extended)
ğŸ”¹ **ğŸ›¡ï¸ Production Ready** â€“ Docker deployment, monitoring, error handling (15/15)
ğŸ”¹ **âš¡ Advanced Features** â€“ Memory management, guardrails, confidence scoring (Extended)

---

## ğŸ’« Demo Usage <a name="demo"></a>

<div align="center">
  
![Demo](assets/Vid.gif)

<p><em>ğŸ¬ Multi-Agent Crypto Assistant in Action - Real-time Analysis & Intelligence</em></p>
</div>

---


### ğŸ”§ **Technology Stack**
- **ğŸ¤– Multi-Agent Framework**: LangGraph + LangChain
- **ğŸ§  LLM & Embedding**: OpenAI GPT-4o + text-embedding-3-small
- **ğŸ“š Vector Database**: Qdrant Cloud (Hybrid Search)
- **ğŸ” Document Processing**: Docling (Advanced PDF/Image parsing)
- **ğŸ“Š Data Storage**: MongoDB + Redis caching
- **ğŸš€ Deployment**: Docker + FastAPI
- **â˜ï¸ AI Services**: Azure ML Endpoints (CryptoBERT + FinBERT-FLS)



## âœ¨ Key Features  <a name="key-features"></a>

### ğŸ”¥ **LLM/RAG Pipeline**
- **ğŸ“š Complete Document Processing**: PDF parsing, text extraction, image summarization with Docling
- **ğŸ§  Semantic Chunking**: GPT-4o-mini powered intelligent text segmentation (256-512 tokens)
- **ğŸ” Hybrid Search**: BM25 sparse + Dense vector search in Qdrant Cloud
- **âš¡ Intelligent Retrieval**: Query expansion, cross-encoder reranking, confidence scoring
- **ğŸ“Š Source Citations**: Direct links to reference documents and images in responses

### ğŸ¤– **Multi-Agent Architecture**
- **ğŸ¯ Specialized Agents**: RAG, Web Search, Sentiment Analysis, Forward-Looking Detection
- **ğŸ”„ LangGraph Orchestration**: State management, conditional routing, agent handoffs
- **ğŸ’¬ Conversation Management**: Memory persistence, context awareness, session handling
- **ğŸ›¡ï¸ Guardrails**: Input/output validation, safety filters, bias detection

### ğŸ“Š **Analytics & Monitoring (Extended Feature)**
- **ğŸ“ˆ Usage Statistics**: Query logging, response time monitoring, error tracking
- **ğŸ“Š Agent Performance**: Success rate monitoring, utilization statistics
- **ğŸ” System Health**: Memory usage monitoring, API call tracking
- **ğŸ’¬ Conversation Analytics**: Chat history storage, context awareness

### ğŸ›¡ï¸ **Production-Ready Infrastructure **
- **ğŸ³ Docker Deployment**: Complete containerization with health checks
- **ğŸ“ Structured Logging**: Comprehensive logging, error tracking, performance monitoring
- **ğŸ”’ Security**: API key management, rate limiting, input sanitization
- **ğŸ’¾ Data Persistence**: Redis caching, MongoDB sessions for conversation memory

### âš¡ **Advanced AI Features (Extended)**
- **ğŸ”® Confidence Scoring**: Response reliability assessment with confidence scores
- **ğŸ¯ Agent Routing**: Intelligent query classification and agent selection, combination usage of agents 
- **ğŸ’¾ Memory Management**: Long-term conversation storage, context retention
- **ğŸŒ Real-time Integration**: Live market data integration through web search


## ğŸ“‹ Technical Capabilities  <a name="technical-capabilities"></a>

### **âœ… Implemented Features**

**ğŸ”¥ Core LLM/RAG Pipeline**
- âœ… **Document Processing**: PDF parsing vá»›i Docling, text extraction, image summarization
- âœ… **Semantic Chunking**: GPT-4o-mini powered intelligent segmentation (256-512 tokens)
- âœ… **Hybrid Vector Search**: BM25 sparse + Dense embeddings in Qdrant Cloud
- âœ… **Intelligent Retrieval**: Query expansion, cross-encoder reranking with confidence scoring
- âœ… **Source Citations**: Direct links to reference documents and images

**ğŸ¤– Multi-Agent Architecture**
- âœ… **Specialized Agents**: RAG, Web Search, Crypto Sentiment Analysis, Forward-Looking Statement Detection
- âœ… **LangGraph Orchestration**: State management, conditional routing, agent handoffs
- âœ… **Conversation Management**: Memory persistence vá»›i MongoDB + Redis caching
- âœ… **Guardrails System**: Input/output validation, safety filters, bias detection

**ğŸ“Š Analytics & Monitoring**
- âœ… **Usage Tracking**: Query logging, response time monitoring, error tracking
- âœ… **Agent Performance**: Success rate monitoring, utilization statistics
- âœ… **System Health**: Memory usage monitoring, API call tracking
- âœ… **Conversation Management**: Chat history storage, context awareness

**ğŸ›¡ï¸ Production-Ready Infrastructure**
- âœ… **Docker Deployment**: Complete containerization vá»›i health checks vÃ  auto-restart
- âœ… **Structured Logging**: Comprehensive logging vá»›i Loguru, error tracking
- âœ… **Security Features**: API key management, rate limiting, input sanitization
- âœ… **Data Persistence**: Redis caching, MongoDB sessions for conversation memory

---

## ğŸš€ Installation & Setup  <a name="installation-setup"></a>

### âš¡ **Prerequisites** <a name="prerequisites"></a>

**Required Software:**
- ğŸ³ [Docker](https://docs.docker.com/get-docker/) & [Docker Compose](https://docs.docker.com/compose/install/)
- ğŸ Python 3.11+ (if running manually)
- ğŸ“¦ Git

**API Keys Required:**
- ğŸ”‘ OpenAI API Key (for LLM and embeddings)
- â˜ï¸ Qdrant Cloud (recommended for production)
- ğŸ” Tavily Web Search API
- ğŸ¤— Hugging Face Token (for reranking model)
- â˜ï¸ Azure ML API Keys (for specialized models)

> [!NOTE]
> Get your API keys from respective services and add them to the `.env` file. See [Environment Configuration](#environment-configuration) for details.

### ğŸ”§ **Environment Configuration** <a name="environment-configuration"></a>

Create a `.env` file in the project root with the following configuration:

```bash
# =============================================================================
# CORE AI SERVICES
# =============================================================================

# LLM Configuration (OpenAI - gpt-4o used in development)
model_name=gpt-4o
openai_api_key=your_openai_api_key_here

# Embedding Model Configuration (OpenAI - text-embedding-3-small for cost optimization)
embedding_model_name=text-embedding-3-small
embedding_openai_api_key=your_openai_api_key_here

# =============================================================================
# VECTOR DATABASE (Qdrant Cloud - Production Ready)
# =============================================================================

QDRANT_URL=https://your-cluster-url.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key_here

# =============================================================================
# WEB SEARCH & EXTERNAL APIs
# =============================================================================

# Web Search API Key (Free credits available with new Tavily Account)
TAVILY_API_KEY=your_tavily_api_key_here

# Hugging Face Token - using reranker model "ms-marco-TinyBERT-L-6"
HUGGINGFACE_TOKEN=your_huggingface_token_here

# =============================================================================
# AZURE ML SPECIALIZED MODELS
# =============================================================================

# Crypto BERT API Key (Sentiment Analysis)
CRYPTO_BERT_API_KEY=your_crypto_bert_api_key_here

# Forward-Looking Statement Detection API Key
AZURE_ML_API_KEY=your_azure_ml_api_key_here

# =============================================================================
# DATA STORAGE & CACHING
# =============================================================================

# Redis Configuration (using Docker container - SECURE)
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=your_secure_redis_password
REDIS_DB=0

# Caching Configuration
CACHE_TTL_HOURS=24
SESSION_MEMORY_TTL_HOURS=2
ENABLE_CACHING=true

# MongoDB Configuration (Conversation Memory)
MONGODB_URI=your_mongodb_connection_string
MONGODB_DATABASE=crypto_financial_memory
```

> [!IMPORTANT]
> **Setup Instructions:**
> 1. Copy the above configuration to a new `.env` file in your project root
> 2. Replace all `your_*_here` placeholders with your actual API keys
> 3. Never commit the `.env` file with real keys to version control
> 4. Rotate API keys regularly in production
> 5. Monitor usage in OpenAI/Azure dashboards

### ğŸ³ **Docker Deployment (Recommended)** <a name="docker-deployment"></a>

#### **Quick Start (3 commands)**
```bash
# 1. Clone repository
git clone <repository-url>
cd Multi-Agent-Crypto-Assistant

# 2. Create .env file with your API keys
# Copy the entire .env configuration from the "Environment Configuration" section above
# Create a new file named .env and replace all placeholders with your actual API keys

# 3. Deploy with Docker Compose
docker-compose up -d
```

#### **Service Architecture**
```bash
ğŸ“¦ SERVICES STARTED:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ crypto-assistant    â†’ Main FastAPI application
ğŸ—„ï¸  crypto-redis       â†’ Redis cache & sessions

#### **Health Monitoring**
```bash
# Check service status
docker-compose ps

# View application logs
docker-compose logs crypto-assistant

# Monitor resource usage
docker stats

# Application available at: http://localhost:8000
```

#### **Document Ingestion**
```bash
# Ingest sample document (from host)
python ingest_rag_data.py --file ./data/raw/coinbase.pdf

# Or from Docker container
docker exec crypto-assistant python ingest_rag_data.py --file ./data/raw/coinbase.pdf

# Batch ingestion
python ingest_rag_data.py --dir ./data/raw/
```

### ğŸ”§ **Manual Installation** <a name="manual-installation"></a>

#### **Environment Setup**
```bash
# Create virtual environment
python -m venv crypto-assistant-env
source crypto-assistant-env/bin/activate  # Linux/Mac
# crypto-assistant-env\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "import langchain, fastapi, qdrant_client; print('âœ… Dependencies installed successfully')"
```

#### **Configuration & Startup**
```bash
# Create .env file manually
# Copy the entire .env configuration from the "Environment Configuration" section above
# Create a new file named .env and replace all placeholders with your actual API keys

# Start application
python app.py

# Application available at: http://localhost:8000
```

---

## ğŸ’» Usage  <a name="usage"></a>

### **ğŸ¯ Getting Started**

1. **ğŸ“– Access the Web Interface**
   - Open [http://localhost:8000](http://localhost:8000)
   - Start chatting with the AI assistant

2. **ğŸš€ Ingest Your Documents**
```bash  
   # Single document
   python ingest_rag_data.py --file ./data/raw/your-document.pdf

   # Multiple documents
   python ingest_rag_data.py --dir ./data/raw/

   # Reset and re-ingest
   python ingest_rag_data.py --reset --dir ./data/raw/
   ```




<p align="center">
  <strong>ğŸ¯ Built for the Future of AI-Powered Financial Analysis</strong>
</p>

